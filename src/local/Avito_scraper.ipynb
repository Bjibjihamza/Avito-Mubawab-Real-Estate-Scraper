{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "39e35241-ec24-48d7-80e1-6cd3c2bf7720",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "spark = SparkSession.builder.appName(\"RealEstate_Avito_Docker\").getOrCreate()\n",
    "\n",
    "storage_account = \"strealestatehamza\"\n",
    "container = \"realestate\"\n",
    "\n",
    "adls_key = os.getenv(\"ADLS_ACCOUNT_KEY\")\n",
    "if not adls_key:\n",
    "    raise RuntimeError(\"ADLS_ACCOUNT_KEY missing from .env\")\n",
    "\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account}.dfs.core.windows.net\",\n",
    "    adls_key,\n",
    ")\n",
    "spark.conf.set(\n",
    "    f\"fs.azure.account.key.{storage_account}.blob.core.windows.net\",\n",
    "    adls_key,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "593fc7f2-87fd-43db-9468-2b0c783c5e38",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 1 : Imports et Configuration\n",
    "# ========================================\n",
    "import re\n",
    "import csv\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from typing import List, Dict, Any\n",
    "from urllib.parse import urljoin\n",
    "from datetime import datetime\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "BASE_URL = \"https://www.avito.ma\"\n",
    "\n",
    "HEADERS = {\n",
    "    \"User-Agent\": (\n",
    "        \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
    "        \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
    "        \"Chrome/120.0 Safari/537.36\"\n",
    "    )\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ca58deca-3141-4035-8560-b20415ff4c82",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 2 : Fonctions basiques\n",
    "# ========================================\n",
    "\n",
    "def fetch_html(url: str) -> str:\n",
    "    \"\"\"T√©l√©charge le HTML d'une page Avito.\"\"\"\n",
    "    resp = requests.get(url, headers=HEADERS, timeout=20)\n",
    "    resp.raise_for_status()\n",
    "    return resp.text\n",
    "\n",
    "\n",
    "def extract_id_from_url(url: str) -> str:\n",
    "    \"\"\"Extrait l'ID num√©rique √† la fin de l'URL Avito.\"\"\"\n",
    "    m = re.search(r\"_([0-9]+)\\.htm$\", url.split(\"?\")[0])\n",
    "    return m.group(1) if m else \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef538575-d61a-4f75-93c0-7ebd5ae87f32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 3 : breadcrumbs, cat√©gorie, localisation & date\n",
    "# ========================================\n",
    "\n",
    "def get_breadcrumbs(soup: BeautifulSoup) -> Dict[str, Any]:\n",
    "    \"\"\"Retourne breadcrumbs_list et breadcrumbs (string)\"\"\"\n",
    "    crumbs = []\n",
    "    ol = soup.find(\"ol\", class_=re.compile(r\"sc-16q833i-0\"))\n",
    "    if ol:\n",
    "        for li in ol.find_all(\"li\", class_=re.compile(r\"sc-16q833i-3\")):\n",
    "            span_or_a = li.find([\"a\", \"span\"])\n",
    "            if span_or_a:\n",
    "                text = span_or_a.get_text(strip=True)\n",
    "                if text:\n",
    "                    crumbs.append(text)\n",
    "\n",
    "    return {\n",
    "        \"breadcrumbs_list\": crumbs,\n",
    "        \"breadcrumbs\": \" > \".join(crumbs) if crumbs else \"\",\n",
    "    }\n",
    "\n",
    "\n",
    "def get_category_label(soup: BeautifulSoup) -> str:\n",
    "    \"\"\"\n",
    "    R√©cup√®re le libell√© de cat√©gorie du bloc 'Categorie' (ex: 'Appartements, √† louer').\n",
    "    \"\"\"\n",
    "    cat_section = soup.find(\"div\", attrs={\"aria-label\": re.compile(r\"Category \")})\n",
    "    if not cat_section:\n",
    "        return \"\"\n",
    "\n",
    "    texts = cat_section.stripped_strings\n",
    "    for t in texts:\n",
    "        if \"Categorie\" in t:\n",
    "            continue\n",
    "        return t\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_location_and_date(soup: BeautifulSoup) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    R√©cup√®re location et published_date_raw.\n",
    "    Ajoute √©galement scraping_time comme Mubawab.\n",
    "    \"\"\"\n",
    "    location = \"\"\n",
    "    published_date_raw = \"\"\n",
    "\n",
    "    # Date de publication depuis balise <time>\n",
    "    time_tag = soup.find(\"time\", attrs={\"datetime\": True})\n",
    "    if time_tag:\n",
    "        published_date_raw = time_tag[\"datetime\"]\n",
    "\n",
    "    # Location (ex: Racine, Casablanca)\n",
    "    location_span = None\n",
    "    for svg in soup.find_all(\"svg\", title=re.compile(r\"MapPinFill Icon\")):\n",
    "        parent = svg.parent\n",
    "        location_span = parent.find(\"span\", class_=re.compile(r\"sc-16573058-17\"))\n",
    "        if location_span:\n",
    "            break\n",
    "\n",
    "    if location_span:\n",
    "        location = location_span.get_text(strip=True)\n",
    "\n",
    "    # Temps de scraping (comme Mubawab)\n",
    "    scraping_time = datetime.utcnow()\n",
    "    scraping_time_iso = scraping_time.isoformat()\n",
    "\n",
    "    return {\n",
    "        \"location\": location,\n",
    "        \"published_date\": published_date_raw,  # Harmonisation avec Mubawab\n",
    "        \"scraping_time\": scraping_time_iso,\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cdaa6f17-1fa0-419d-aabc-33c8cc0fe667",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 4 : titre, prix, description, images\n",
    "# ========================================\n",
    "\n",
    "def get_title_and_price(soup: BeautifulSoup) -> Dict[str, str]:\n",
    "    \"\"\"R√©cup√®re le titre (h1) et le prix.\"\"\"\n",
    "    title = \"\"\n",
    "    price_text = \"\"\n",
    "\n",
    "    # Titre\n",
    "    h1 = soup.find(\"h1\")\n",
    "    if h1:\n",
    "        title = h1.get_text(strip=True)\n",
    "\n",
    "    # Prix\n",
    "    price_block = soup.find(\"div\", class_=re.compile(r\"sc-16573058-10\"))\n",
    "    if price_block:\n",
    "        p = price_block.find(\"p\")\n",
    "        if p:\n",
    "            price_text = p.get_text(strip=True)\n",
    "    else:\n",
    "        p = soup.find(string=re.compile(r\"DH\"))\n",
    "        if p:\n",
    "            price_text = p.strip()\n",
    "\n",
    "    return {\n",
    "        \"title\": title,\n",
    "        \"price_text\": price_text,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_description(soup: BeautifulSoup) -> str:\n",
    "    \"\"\"R√©cup√®re la description depuis le bloc Description.\"\"\"\n",
    "    desc_container = None\n",
    "    for div in soup.find_all(\"div\", class_=re.compile(r\"sc-b59a33d2-3\")):\n",
    "        h2 = div.find(\"h2\")\n",
    "        if h2 and \"Description\" in h2.get_text():\n",
    "            desc_container = div\n",
    "            break\n",
    "\n",
    "    if desc_container:\n",
    "        text_parts = []\n",
    "        for node in desc_container.find_all([\"p\", \"div\", \"span\"], recursive=True):\n",
    "            t = node.get_text(\" \", strip=True)\n",
    "            if t:\n",
    "                text_parts.append(t)\n",
    "        description = \" \".join(text_parts)\n",
    "        description = re.sub(r\"\\s+\", \" \", description).strip()\n",
    "        return description\n",
    "\n",
    "    # fallback\n",
    "    p = soup.find(\"p\")\n",
    "    if p:\n",
    "        return p.get_text(\" \", strip=True)\n",
    "    return \"\"\n",
    "\n",
    "\n",
    "def get_images(soup: BeautifulSoup) -> List[str]:\n",
    "    \"\"\"R√©cup√®re toutes les URLs d'images de la galerie principale.\"\"\"\n",
    "    urls = []\n",
    "    for img in soup.select(\"div.picture img\"):\n",
    "        src = img.get(\"src\")\n",
    "        if src and \"content.avito.ma/classifieds/images\" in src:\n",
    "            if src not in urls:\n",
    "                urls.append(src)\n",
    "    return urls\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "07196b50-7204-421e-92f6-f55703153389",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 5 : attributs, √©quipements, infos vendeur\n",
    "# ========================================\n",
    "\n",
    "def get_attributes_and_equipments(soup: BeautifulSoup) -> Dict[str, Any]:\n",
    "    \"\"\"\n",
    "    R√©cup√®re :\n",
    "      - attributes: dict { \"Chambres\": \"3\", \"Salle de bain\": \"2\", ... }\n",
    "      - equipments: liste [\"Ascenseur\", \"Balcon\", ...]\n",
    "    \"\"\"\n",
    "    attributes = {}\n",
    "    equipments = []\n",
    "\n",
    "    attr_blocks = soup.find_all(\"div\", class_=re.compile(r\"sc-cd1c365e-0\"))\n",
    "    for block in attr_blocks:\n",
    "        parent = block.find_parent(\"div\", class_=re.compile(r\"sc-b59a33d2-3\"))\n",
    "        is_equip_section = False\n",
    "        if parent:\n",
    "            h2 = parent.find(\"h2\")\n",
    "            if h2 and \"√âquipements\" in h2.get_text():\n",
    "                is_equip_section = True\n",
    "\n",
    "        for item in block.find_all(\"div\", class_=re.compile(r\"sc-cd1c365e-1\")):\n",
    "            img = item.find(\"img\", alt=True)\n",
    "            label_from_alt = img[\"alt\"].strip() if img else \"\"\n",
    "\n",
    "            value_span = item.find(\"span\", class_=re.compile(r\"fjZBup\"))\n",
    "            value = value_span.get_text(strip=True) if value_span else \"\"\n",
    "\n",
    "            if is_equip_section:\n",
    "                if label_from_alt:\n",
    "                    equipments.append(label_from_alt)\n",
    "                elif value:\n",
    "                    equipments.append(value)\n",
    "            else:\n",
    "                if label_from_alt and value:\n",
    "                    attributes[label_from_alt] = value\n",
    "\n",
    "    return {\n",
    "        \"attributes\": attributes,\n",
    "        \"equipments\": equipments,\n",
    "    }\n",
    "\n",
    "\n",
    "def get_seller_info(soup: BeautifulSoup) -> Dict[str, Any]:\n",
    "    \"\"\"R√©cup√®re seller_name, seller_url, seller_is_store.\"\"\"\n",
    "    seller_name = \"\"\n",
    "    seller_url = \"\"\n",
    "    seller_is_store = False\n",
    "\n",
    "    seller_block = soup.find(\"div\", attrs={\"data-test\": \"av_sellerInfo\"})\n",
    "    if not seller_block:\n",
    "        seller_block = soup.find(\"div\", class_=re.compile(r\"sc-1l0do2b-0\"))\n",
    "\n",
    "    if seller_block:\n",
    "        a = seller_block.find(\"a\", href=True)\n",
    "        if a:\n",
    "            seller_url = urljoin(BASE_URL, a[\"href\"])\n",
    "            name_tag = a.find(\"p\") or a.find(\"span\")\n",
    "            if name_tag:\n",
    "                seller_name = name_tag.get_text(strip=True)\n",
    "\n",
    "        text_block = seller_block.get_text(\" \", strip=True)\n",
    "        if \"Voir la boutique\" in text_block:\n",
    "            seller_is_store = True\n",
    "\n",
    "        if seller_block.find(\"title\", string=re.compile(r\"Store Icon\")):\n",
    "            seller_is_store = True\n",
    "\n",
    "    return {\n",
    "        \"seller_name\": seller_name,\n",
    "        \"seller_url\": seller_url,\n",
    "        \"seller_is_store\": seller_is_store,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0dd8fa17-84bb-4a0f-ab80-a21dbe65e14d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 6 : Parser principal\n",
    "# ========================================\n",
    "\n",
    "def parse_avito_ad(url: str) -> Dict[str, Any]:\n",
    "    \"\"\"Scrape une annonce Avito et retourne un dict.\"\"\"\n",
    "    html = fetch_html(url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    ad_id = extract_id_from_url(url)\n",
    "\n",
    "    crumbs = get_breadcrumbs(soup)\n",
    "    cat_label = get_category_label(soup)\n",
    "    loc_date = get_location_and_date(soup)\n",
    "    title_price = get_title_and_price(soup)\n",
    "    description = get_description(soup)\n",
    "    images = get_images(soup)\n",
    "    attrs_equip = get_attributes_and_equipments(soup)\n",
    "    seller = get_seller_info(soup)\n",
    "\n",
    "    ad_data: Dict[str, Any] = {\n",
    "        \"id\": ad_id,\n",
    "        \"url\": url,\n",
    "        \"title\": title_price[\"title\"],\n",
    "        \"price_text\": title_price[\"price_text\"],\n",
    "        \"location\": loc_date[\"location\"],\n",
    "        \"published_date\": loc_date[\"published_date\"],\n",
    "        \"scraping_time\": loc_date[\"scraping_time\"],\n",
    "        \"breadcrumbs_list\": crumbs[\"breadcrumbs_list\"],\n",
    "        \"breadcrumbs\": crumbs[\"breadcrumbs\"],\n",
    "        \"category_label\": cat_label,\n",
    "        \"description\": description,\n",
    "        \"images\": images,\n",
    "        \"attributes\": attrs_equip[\"attributes\"],\n",
    "        \"equipments\": attrs_equip[\"equipments\"],\n",
    "        \"seller_name\": seller[\"seller_name\"],\n",
    "        \"seller_url\": seller[\"seller_url\"],\n",
    "        \"seller_is_store\": seller[\"seller_is_store\"],\n",
    "    }\n",
    "\n",
    "    return ad_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "beeb91b5-bc6a-42f2-bd2c-d41b47349cca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 7 : extraire URLs depuis listing\n",
    "# ========================================\n",
    "\n",
    "def get_ad_urls_from_listing(listing_url: str) -> List[str]:\n",
    "    \"\"\"R√©cup√®re toutes les URLs d'annonces d'une page listing Avito.\"\"\"\n",
    "    html = fetch_html(listing_url)\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    ad_urls = set()\n",
    "\n",
    "    for a in soup.find_all(\"a\", href=True):\n",
    "        href = a[\"href\"]\n",
    "\n",
    "        if href.startswith(\"/\"):\n",
    "            href = urljoin(BASE_URL, href)\n",
    "\n",
    "        if \"avito.ma\" not in href:\n",
    "            continue\n",
    "\n",
    "        if re.search(r\"_[0-9]+\\.htm$\", href):\n",
    "            clean = href.split(\"?\")[0]\n",
    "            ad_urls.add(clean)\n",
    "\n",
    "    ad_urls = sorted(ad_urls)\n",
    "    print(f\"üåê Trouv√© {len(ad_urls)} annonces sur {listing_url}\")\n",
    "    return ad_urls\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "85eef70f-0184-4472-9a0e-3ecba21dbe40",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 8 : Save CSV (optionnel)\n",
    "# ========================================\n",
    "\n",
    "def save_ads_to_csv(ad_dicts: List[Dict[str, Any]], filename: str) -> None:\n",
    "    \"\"\"Sauvegarde une liste d'annonces (dict) dans un fichier CSV.\"\"\"\n",
    "    if not ad_dicts:\n",
    "        print(f\"Aucune annonce √† sauvegarder pour {filename}\")\n",
    "        return\n",
    "\n",
    "    fieldnames = [\n",
    "        \"id\",\n",
    "        \"url\",\n",
    "        \"title\",\n",
    "        \"price_text\",\n",
    "        \"location\",\n",
    "        \"published_date\",\n",
    "        \"scraping_time\",\n",
    "        \"breadcrumbs\",\n",
    "        \"breadcrumbs_list\",\n",
    "        \"category_label\",\n",
    "        \"description\",\n",
    "        \"attributes\",\n",
    "        \"equipments\",\n",
    "        \"seller_name\",\n",
    "        \"seller_url\",\n",
    "        \"seller_is_store\",\n",
    "    ]\n",
    "\n",
    "    with open(filename, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "\n",
    "        for ad in ad_dicts:\n",
    "            row: Dict[str, Any] = {}\n",
    "\n",
    "            for key in fieldnames:\n",
    "                if key in (\"attributes\", \"equipments\", \"breadcrumbs_list\"):\n",
    "                    continue\n",
    "                row[key] = ad.get(key, \"\")\n",
    "\n",
    "            row[\"attributes\"] = json.dumps(\n",
    "                ad.get(\"attributes\", {}), ensure_ascii=False\n",
    "            )\n",
    "            row[\"equipments\"] = \"; \".join(ad.get(\"equipments\", []))\n",
    "            row[\"breadcrumbs_list\"] = json.dumps(\n",
    "                ad.get(\"breadcrumbs_list\", []), ensure_ascii=False\n",
    "            )\n",
    "\n",
    "            writer.writerow(row)\n",
    "\n",
    "    print(f\"‚úÖ Sauvegard√© {len(ad_dicts)} annonces dans {filename}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "25211b32-86f5-4a7f-94a7-673fd6200b3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# ========================================\n",
    "# CELLULE 9 : scraper listing -> liste\n",
    "# ========================================\n",
    "\n",
    "def scrape_listing_to_list(listing_url: str) -> List[Dict[str, Any]]:\n",
    "    \"\"\"Scrape la 1√®re page d'un listing Avito et retourne une liste de dicts.\"\"\"\n",
    "    ad_urls = get_ad_urls_from_listing(listing_url)\n",
    "\n",
    "    all_ads: List[Dict[str, Any]] = []\n",
    "    total = len(ad_urls)\n",
    "\n",
    "    for i, ad_url in enumerate(ad_urls, 1):\n",
    "        print(f\"[{i}/{total}] Scraping {ad_url}\")\n",
    "        try:\n",
    "            ad_data = parse_avito_ad(ad_url)\n",
    "            all_ads.append(ad_data)\n",
    "        except Exception as e:\n",
    "            print(f\"  ‚ùå Erreur sur {ad_url}: {e}\")\n",
    "\n",
    "        time.sleep(random.uniform(1.0, 2.5))\n",
    "\n",
    "    return all_ads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "165d6113-fa57-44d0-af8c-ad9048edc4de",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üåê Trouv√© 38 annonces sur https://www.avito.ma/fr/maroc/ventes_immobilieres-√†_vendre\n",
      "[1/38] Scraping https://www.avito.ma/fr/agdal/terrains_et_fermes/Terrain_bijoux_R5_AGDAL_53485705.htm\n",
      "[2/38] Scraping https://www.avito.ma/fr/aouama_gharbia/maisons/maison_semi_fini_√†_vendre_√†_lot_sanaoubari_56970217.htm\n",
      "[3/38] Scraping https://www.avito.ma/fr/autre_secteur/terrains_et_fermes/Terrain_agricole_√©quip√©_√†_Benimadane_√†_vendre_ou_43988341.htm\n",
      "[4/38] Scraping https://www.avito.ma/fr/autre_secteur/villas_et_riads/Villa_neuve_√†_vendre_670_m¬≤_√†_Temara_54973482.htm\n",
      "[5/38] Scraping https://www.avito.ma/fr/beaus√©jour/appartements/Appartement_√†_vendre_115_m¬≤_√†_Casablanca_55194354.htm\n",
      "[6/38] Scraping https://www.avito.ma/fr/bir_rami/appartements/Appartement_√†_vendre_65_m¬≤_√†_K√©nitra_57164756.htm\n",
      "[7/38] Scraping https://www.avito.ma/fr/bouskoura_centre/terrains_et_fermes/Terrain_√†_vendre_bouskoura_54038488.htm\n",
      "[8/38] Scraping https://www.avito.ma/fr/branes_2/appartements/Appartement_√†_vendre_57133042.htm\n",
      "[9/38] Scraping https://www.avito.ma/fr/californie/appartements/CMN_AC_2045___Appartement_√†_vendre_√†_Californie_57240145.htm\n",
      "[10/38] Scraping https://www.avito.ma/fr/centre/appartements/Appartement_√†_vendre_situ√©_√†_Mimosas_56069360.htm\n",
      "[11/38] Scraping https://www.avito.ma/fr/centre_ville/villas_et_riads/Villa_spacieuse_avec_potentiel_d_agrandissement_56287133.htm\n",
      "[12/38] Scraping https://www.avito.ma/fr/dar_bouazza/appartements/Studio_√†_vendre_Dar_Bouazza_57148246.htm\n",
      "[13/38] Scraping https://www.avito.ma/fr/gu√©liz/appartements/Appartement_Neuf_84_m¬≤_√†_Gu√©liz_Avec_Piscine_56259750.htm\n",
      "[14/38] Scraping https://www.avito.ma/fr/gu√©liz/appartements/Appartement_avec_grand_terrasse_√†_Gu√©liz_55811861.htm\n",
      "[15/38] Scraping https://www.avito.ma/fr/gu√©liz/local/Local_commercial_39_m_√†_vendre_√†_Marrakech_Gu√©liz_56387295.htm\n",
      "[16/38] Scraping https://www.avito.ma/fr/hay_hassani/appartements/Appartement_meubl√©_de_28_m2_√†_Hay_Hassani_54789238.htm\n",
      "[17/38] Scraping https://www.avito.ma/fr/hay_kassam/terrains_et_fermes/Vente_terrain_pour_villa_56688970.htm\n",
      "[18/38] Scraping https://www.avito.ma/fr/hay_mohammadi/local/Appartement_RDC_avec_Magasin_√†_vendre_√†_H_M_Casablanca_53754916.htm\n",
      "[19/38] Scraping https://www.avito.ma/fr/la_gironde/appartements/CMN_ME_1629___Appartement_√†_vendre_√†_La_Gironde_56163658.htm\n",
      "[20/38] Scraping https://www.avito.ma/fr/la_gironde/appartements/CMN_ME_1682___Appartement_√†_vendre_√†_La_Gironde_57234393.htm\n",
      "[21/38] Scraping https://www.avito.ma/fr/les_oudayas/villas_et_riads/riad_vue_sur_mer_en_vente_aux_oudayas_57101452.htm\n",
      "[22/38] Scraping https://www.avito.ma/fr/majorelle/appartements/Bel_Appartement_les_Jardins_Majorelle_57240162.htm\n",
      "[23/38] Scraping https://www.avito.ma/fr/marjane_2/local/Fonds_de_commerce_avec_affaire_qui_marche_bien_57240161.htm\n",
      "[24/38] Scraping https://www.avito.ma/fr/martil/appartements/Appartements_enregistr√©s_√†_vendre_avec_place_de_parking_56704633.htm\n",
      "[25/38] Scraping https://www.avito.ma/fr/mers_sultan/appartements/Appart_2ch_dble_sal_blc_97m2_√†_vendre_Mers_sultan_56565747.htm\n",
      "[26/38] Scraping https://www.avito.ma/fr/mozart/appartements/Appartement_√†_vendre_126_m¬≤_√†_Tanger_57144818.htm\n",
      "[27/38] Scraping https://www.avito.ma/fr/oulfa/appartements/CMN_HA_1756___Appartement_√†_vendre_√†_Oulfa_56436198.htm\n",
      "[28/38] Scraping https://www.avito.ma/fr/route_d_ourika/villas_et_riads/Villa_√†_vendre_√†_28_km_de_Marrakech_57240140.htm\n",
      "[29/38] Scraping https://www.avito.ma/fr/saidia/appartements/Appartement_√†_vendre_60_m¬≤_√†_Saidia_55901203.htm\n",
      "[30/38] Scraping https://www.avito.ma/fr/sefrou/terrains_et_fermes/Terrain_agricole_cl√¥tur√©_et_titr√©_√†_vendre_pr√®s_de_Sefrou_57231452.htm\n",
      "[31/38] Scraping https://www.avito.ma/fr/sidi_bernoussi/appartements/Appartement_√†_vendre_64_m¬≤_√†_Casablanca_37621456.htm\n",
      "[32/38] Scraping https://www.avito.ma/fr/sidi_maarouf/appartements/Appartement_57_m√®tre_Sidi_Maroof_57232236.htm\n",
      "[33/38] Scraping https://www.avito.ma/fr/sidi_maarouf/appartements/Appartement_Duplex_√†_vendre_140_m¬≤_√†_Casablanca_56693326.htm\n",
      "[34/38] Scraping https://www.avito.ma/fr/sidi_othmane/local/Maison_92m2_RDC_Commercial_2√©tages_Hay_Raja_Casa__54879803.htm\n",
      "[35/38] Scraping https://www.avito.ma/fr/souissi/terrains_et_fermes/Tr√®s_bon_terrain_angle_rue_bani_ourraine_53698927.htm\n",
      "[36/38] Scraping https://www.avito.ma/fr/targa/villas_et_riads/Villa_moderne_√†_Targa___Opportunit√©_rare_57240163.htm\n",
      "[37/38] Scraping https://www.avito.ma/fr/tit_mellil/autre_immobilier/Terrain_industriel_√†_vendre_56504447.htm\n",
      "[38/38] Scraping https://www.avito.ma/fr/yassmine/villas_et_riads/Villa_contemporaine_face_mer___Yassmine_Mohammedia_56639909.htm\n",
      "üåê Trouv√© 38 annonces sur https://www.avito.ma/fr/maroc/locations_immobilieres-√†_louer\n",
      "[1/38] Scraping https://www.avito.ma/fr/2_mars/local/93__bd_d_Anoual_BEAUX_LOCAUX_Zone_Tr√®s_ANIM√âE_56651118.htm\n",
      "[2/38] Scraping https://www.avito.ma/fr/agdal/appartements/Appartement_Neuf_√†_louer_Rabat_agdal_57045840.htm\n",
      "[3/38] Scraping https://www.avito.ma/fr/agdal/appartements/Appartement_√†_louer_situ√©_√†_Haut_Agdal_56219653.htm\n",
      "[4/38] Scraping https://www.avito.ma/fr/ain_sebaa/appartements/Appartement_meubl√©_√†_louer_110_m¬≤_√†_Ain_sbaa_57173076.htm\n",
      "[5/38] Scraping https://www.avito.ma/fr/anfa/appartements/Studio_meubl√©_Fille_Anfa_57079211.htm\n",
      "[6/38] Scraping https://www.avito.ma/fr/autre_secteur/local/MHD_AI_1002___Commerce_√†_louer_√†_Zone_industrielle_57240146.htm\n",
      "[7/38] Scraping https://www.avito.ma/fr/autre_secteur/villas_et_riads/Villa_location_√†_bouskoura_ville_verte_56019804.htm\n",
      "[8/38] Scraping https://www.avito.ma/fr/beaus√©jour/appartements/Garsonnier_meubl√©_57240134.htm\n",
      "[9/38] Scraping https://www.avito.ma/fr/belv√©d√®re/appartements/Appartement_64m¬≤_Belv√©d√®re_56619912.htm\n",
      "[10/38] Scraping https://www.avito.ma/fr/bourgogne/appartements/CMN_AN_1849___Appartement_√†_louer_√†_Bourgogne_57234359.htm\n",
      "[11/38] Scraping https://www.avito.ma/fr/bouskoura_centre/bureaux/Plateaux_bureau_location_54022102.htm\n",
      "[12/38] Scraping https://www.avito.ma/fr/boustane/appartements/Location_appartement_Aswak_salam_√†_Oujda_53600571.htm\n",
      "[13/38] Scraping https://www.avito.ma/fr/c.i.l/appartements/Appartement_√†_louer_150_m¬≤_√†_Casablanca_57039423.htm\n",
      "[14/38] Scraping https://www.avito.ma/fr/casablanca_finance_city/appartements/appartement_meubl√©_√†_louer_√†_CFC_57015502.htm\n",
      "[15/38] Scraping https://www.avito.ma/fr/centre_ville/appartements/Appartement_meubl√©_de_luxe_√†_louer_longue_dur√©e_57240139.htm\n",
      "[16/38] Scraping https://www.avito.ma/fr/centre_ville/bureaux/Bureaux_√†_louer_secteur_administratif_centre_57129327.htm\n",
      "[17/38] Scraping https://www.avito.ma/fr/ferme_bretone/appartements/Studio_vide_√†_louer_sur_ferme_Bretone_57226046.htm\n",
      "[18/38] Scraping https://www.avito.ma/fr/gauthier/appartements/Appartement_73m_Gauthier_50876083.htm\n",
      "[19/38] Scraping https://www.avito.ma/fr/hamria/bureaux/Plateaux_bureaux_haut_standing_A_LOUER_centre_57224638.htm\n",
      "[20/38] Scraping https://www.avito.ma/fr/hay_al_matar/appartements/Appartement_Meubl√©_Haut_Standing_√†_Louer__53788128.htm\n",
      "[21/38] Scraping https://www.avito.ma/fr/hay_mohammadi/local/Magasin_85m2_et_Cave_212m2_√†_louer_H_M_Casa__56143311.htm\n",
      "[22/38] Scraping https://www.avito.ma/fr/hay_riad/appartements/Hay_Riad__Duplex_de_4chambres_en_location_56731580.htm\n",
      "[23/38] Scraping https://www.avito.ma/fr/hay_riad/villas_et_riads/Villa_√†_louer_sur_Hay_Riad_56834363.htm\n",
      "[24/38] Scraping https://www.avito.ma/fr/les_princesses/appartements/Appartement_Meubl√©_√†_louer_93_m¬≤_√†_Casablanca_56894143.htm\n",
      "[25/38] Scraping https://www.avito.ma/fr/les_princesses/appartements/Appartement_terrasse_meubl√©_Les_Princesses_56542695.htm\n",
      "[26/38] Scraping https://www.avito.ma/fr/lissasfa/appartements/Mon_Appartement_√†_louer_78_m¬≤_√†_Casablanca_57240125.htm\n",
      "[27/38] Scraping https://www.avito.ma/fr/maarif/appartements/Appartement_meubl√©_121_m¬≤_Maarif_57036511.htm\n",
      "[28/38] Scraping https://www.avito.ma/fr/maarif/appartements/Studio_neuf_meubl√©_Maarif_57112495.htm\n",
      "[29/38] Scraping https://www.avito.ma/fr/mabrouka/appartements/Appartement_meubl√©_√†_louer_proche_Gu√©liz_57197216.htm\n",
      "[30/38] Scraping https://www.avito.ma/fr/mers_sultan/bureaux/Bureau_3p_100m2_√†_louer_sur_bd_Mustapha_Maani_56127354.htm\n",
      "[31/38] Scraping https://www.avito.ma/fr/mers_sultan/local/Magasin_16m2_√†_louer_√†_Mers_sultan_56191405.htm\n",
      "[32/38] Scraping https://www.avito.ma/fr/mimosas/appartements/Apprt_studio_mimosas_56298004.htm\n",
      "[33/38] Scraping https://www.avito.ma/fr/oasis/appartements/Studio_neuf_terrasse_meubl√©_63m_Oasis_55930135.htm\n",
      "[34/38] Scraping https://www.avito.ma/fr/roches_noires/appartements/Appartement_vide_√†_louer_√†_roche_noire_57173063.htm\n",
      "[35/38] Scraping https://www.avito.ma/fr/route_de_casablanca/appartements/longue_dur√©e_57193375.htm\n",
      "[36/38] Scraping https://www.avito.ma/fr/sidi_maarouf/appartements/Appartement_√†_louer_44_m¬≤_√†_Casablanca_55740941.htm\n",
      "[37/38] Scraping https://www.avito.ma/fr/tanja_balia/appartements/Appartement_loyer_meubl√©_√†_tanja_balia_56932466.htm\n",
      "[38/38] Scraping https://www.avito.ma/fr/yacoub_el_mansour/local/Immeuble_de_Prestige_en_Location_√†_Rabat_57176013.htm\n",
      "Ventes r√©cup√©r√©es: 38\n",
      "Locations r√©cup√©r√©es: 38\n",
      "üìå Sch√©ma ventes\n",
      "root\n",
      " |-- attributes: string (nullable = true)\n",
      " |-- breadcrumbs: string (nullable = true)\n",
      " |-- breadcrumbs_list: string (nullable = true)\n",
      " |-- category_label: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- equipments: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- images: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- price_text: string (nullable = true)\n",
      " |-- published_date: string (nullable = true)\n",
      " |-- scraping_time: string (nullable = true)\n",
      " |-- seller_is_store: boolean (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      " |-- seller_url: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- source_site: string (nullable = false)\n",
      " |-- offre: string (nullable = false)\n",
      " |-- ingest_ts: string (nullable = false)\n",
      "\n",
      "üìå Sch√©ma locations\n",
      "root\n",
      " |-- attributes: string (nullable = true)\n",
      " |-- breadcrumbs: string (nullable = true)\n",
      " |-- breadcrumbs_list: string (nullable = true)\n",
      " |-- category_label: string (nullable = true)\n",
      " |-- description: string (nullable = true)\n",
      " |-- equipments: string (nullable = true)\n",
      " |-- id: string (nullable = true)\n",
      " |-- images: string (nullable = true)\n",
      " |-- location: string (nullable = true)\n",
      " |-- price_text: string (nullable = true)\n",
      " |-- published_date: string (nullable = true)\n",
      " |-- scraping_time: string (nullable = true)\n",
      " |-- seller_is_store: boolean (nullable = true)\n",
      " |-- seller_name: string (nullable = true)\n",
      " |-- seller_url: string (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- url: string (nullable = true)\n",
      " |-- source_site: string (nullable = false)\n",
      " |-- offre: string (nullable = false)\n",
      " |-- ingest_ts: string (nullable = false)\n",
      "\n",
      "‚úÖ Ventes Avito (PARQUET) -> abfss://realestate@strealestatehamza.dfs.core.windows.net/raw/avito/ventes/2025/11/25/134030\n",
      "‚úÖ Locations Avito (PARQUET) -> abfss://realestate@strealestatehamza.dfs.core.windows.net/raw/avito/locations/2025/11/25/134030\n"
     ]
    }
   ],
   "source": [
    "# ========================================\n",
    "# CELLULE 10 : Workflow Spark + ADLS (Avito, PARQUET)\n",
    "# ========================================\n",
    "from datetime import datetime\n",
    "from pyspark.sql import functions as F\n",
    "import json\n",
    "\n",
    "# üîí Variables stockage ADLS\n",
    "storage_account = \"strealestatehamza\"\n",
    "container = \"realestate\"\n",
    "\n",
    "# --- 1. URLs des listings Avito ---\n",
    "ventes_url = \"https://www.avito.ma/fr/maroc/ventes_immobilieres-√†_vendre\"\n",
    "locations_url = \"https://www.avito.ma/fr/maroc/locations_immobilieres-√†_louer\"\n",
    "\n",
    "# --- 2. Scraping -> listes de dicts ---\n",
    "raw_ventes_ads = scrape_listing_to_list(ventes_url)\n",
    "raw_locations_ads = scrape_listing_to_list(locations_url)\n",
    "\n",
    "print(f\"Ventes r√©cup√©r√©es: {len(raw_ventes_ads)}\")\n",
    "print(f\"Locations r√©cup√©r√©es: {len(raw_locations_ads)}\")\n",
    "\n",
    "\n",
    "def normalize_ads_for_spark(ads):\n",
    "    \"\"\"Convertit les champs dict/list en strings pour Spark (OK aussi pour Parquet).\"\"\"\n",
    "    normalized = []\n",
    "    for ad in ads:\n",
    "        d = ad.copy()\n",
    "        d[\"attributes\"] = json.dumps(d.get(\"attributes\", {}), ensure_ascii=False)\n",
    "        d[\"equipments\"] = \"; \".join(d.get(\"equipments\", []) or [])\n",
    "        d[\"breadcrumbs_list\"] = json.dumps(d.get(\"breadcrumbs_list\", []) or [], ensure_ascii=False)\n",
    "        d[\"images\"] = \", \".join(d.get(\"images\", []) or [])\n",
    "        normalized.append(d)\n",
    "    return normalized\n",
    "\n",
    "\n",
    "ventes_ads = normalize_ads_for_spark(raw_ventes_ads)\n",
    "locations_ads = normalize_ads_for_spark(raw_locations_ads)\n",
    "\n",
    "# --- 3. Conversion en DataFrame Spark ---\n",
    "ventes_df = spark.createDataFrame(ventes_ads)\n",
    "locations_df = spark.createDataFrame(locations_ads)\n",
    "\n",
    "now = datetime.utcnow().isoformat()\n",
    "\n",
    "# Colonnes techniques\n",
    "ventes_df = (\n",
    "    ventes_df\n",
    "    .withColumn(\"source_site\", F.lit(\"avito\"))\n",
    "    .withColumn(\"offre\", F.lit(\"vente\"))\n",
    "    .withColumn(\"ingest_ts\", F.lit(now))\n",
    ")\n",
    "\n",
    "locations_df = (\n",
    "    locations_df\n",
    "    .withColumn(\"source_site\", F.lit(\"avito\"))\n",
    "    .withColumn(\"offre\", F.lit(\"location\"))\n",
    "    .withColumn(\"ingest_ts\", F.lit(now))\n",
    ")\n",
    "\n",
    "# --- Debug schemas ---\n",
    "print(\"üìå Sch√©ma ventes\")\n",
    "ventes_df.printSchema()\n",
    "print(\"üìå Sch√©ma locations\")\n",
    "locations_df.printSchema()\n",
    "\n",
    "# --- 4. Chemins RAW dans ADLS ---\n",
    "date_path = datetime.utcnow().strftime(\"%Y/%m/%d/%H%M%S\")\n",
    "base_path = f\"abfss://{container}@{storage_account}.dfs.core.windows.net/raw\"\n",
    "\n",
    "ventes_path = f\"{base_path}/avito/ventes/{date_path}\"\n",
    "locations_path = f\"{base_path}/avito/locations/{date_path}\"\n",
    "\n",
    "# --- 5. √âcriture en PARQUET (‚ùå plus de CSV) ---\n",
    "(\n",
    "    ventes_df\n",
    "    .coalesce(1)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(ventes_path)\n",
    ")\n",
    "\n",
    "(\n",
    "    locations_df\n",
    "    .coalesce(1)\n",
    "    .write\n",
    "    .mode(\"overwrite\")\n",
    "    .parquet(locations_path)\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Ventes Avito (PARQUET) ->\", ventes_path)\n",
    "print(\"‚úÖ Locations Avito (PARQUET) ->\", locations_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Avito_scraper",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
